{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall workflow\n",
    "![alt text](https://github.com/AIScienceTutorial/Bayesian-optimization---case-study/blob/main/workflow.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For array operations\n",
    "import pandas as pd  # For Dataframe operations (similar to Excel spreadsheets)\n",
    "from scipy.stats import norm\n",
    "\n",
    "# For plotting figures\n",
    "import matplotlib.pyplot as plt  \n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                              AutoMinorLocator)\n",
    "\n",
    "# Machine learning-realated functions\n",
    "from sklearn.preprocessing import StandardScaler # For normalizing inputs\n",
    "from sklearn.decomposition import PCA # Principle component analysis\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C ,WhiteKernel as Wht,Matern as matk\n",
    "\n",
    "from tqdm.auto import tqdm  # progress bar\n",
    "\n",
    "from IPython import display\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SMILES and features into Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"https://github.com/AIScienceTutorial/Bayesian-optimization---case-study/blob/main/features.csv?raw=true\"\n",
    "smiles = \"https://github.com/AIScienceTutorial/Bayesian-optimization---case-study/blob/main/SMILES.csv?raw=true\"\n",
    "\n",
    "# Load SMILES and features\n",
    "dfSMILES = pd.read_csv(smiles)\n",
    "Xsmiles = dfSMILES.SMILES\n",
    "print(Xsmiles)\n",
    "X = pd.read_csv(features)\n",
    "print('Shape of input features = ',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some RDKit links for feature generation: \n",
    "### https://www.rdkit.org/docs/source/rdkit.Chem.Descriptors.html\n",
    "### https://www.rdkit.org/docs/source/rdkit.Chem.rdMolDescriptors.html\n",
    "\n",
    "## To draw 2D molecular structure from SMILES and vice versa: https://pubchem.ncbi.nlm.nih.gov//edit3/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform principle component analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "\n",
    "#Plotting\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Number of PCs', fontsize=30,labelpad=20)\n",
    "ax1.set_ylabel('Cumulative explained variance', fontsize=30,labelpad=20)\n",
    "ax1.xaxis.set_major_locator(MultipleLocator(10))\n",
    "ax1.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax1.tick_params(axis='both', which='major', direction='in', size=8, left='on', bottom='on', width=2, pad=15)\n",
    "ax1.tick_params(axis='both', which='minor', direction='in', size=4, left='on', bottom='on',width=1, pad=15)\n",
    "ax1.tick_params(axis=\"y\", labelsize=20)\n",
    "ax1.tick_params(axis=\"x\", labelsize=20)\n",
    "\n",
    "plt.gcf().set_size_inches((12, 10))\n",
    "#ax1.set_ylim([0.8,1.05])\n",
    "#ax1.set_xlim([-1,28])\n",
    "evr = np.cumsum(pca.explained_variance_ratio_)\n",
    "ax1.plot(evr, marker='^',markersize=16, markeredgecolor='black', \n",
    "         linestyle='-',linewidth=4, color='red')   # Plotting\n",
    "\n",
    "print('{:<20s}{:<80s}'.format('No. of PC','Cumulative explained variance'))\n",
    "print(50*'-')\n",
    "for i,a in enumerate(evr):\n",
    "    if a<=1:\n",
    "        print('{:<20d}{:<80f}'.format(i+1,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_PC = 15  # Set number of principle components\n",
    "st = StandardScaler()\n",
    "Xdata = st.fit_transform(X)  # Normalize feature vectors\n",
    "\n",
    "pca = PCA(n_components=n_PC)\n",
    "Xdata = pca.fit_transform(Xdata)  # Transform feature vectors to PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Gaussian Process Regression model and acquisition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpregression(Xtrain,Ytrain,Nfeature):    \n",
    "    cmean=[1.0]*Nfeature\n",
    "    cbound=[[1e-3, 1e3]]*Nfeature\n",
    "    kernel = C(1.0, (1e-3,1e3)) * matk(cmean,cbound,1.5) + Wht(1.0, (1e-3, 1e3))  # Matern kernel\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=40, normalize_y=False)\n",
    "    gp.fit(Xtrain, Ytrain)\n",
    "    return gp\n",
    "\n",
    "# Predict result using GP regression model\n",
    "def gprediction(gpnetwork,xtest):\n",
    "    y_pred, sigma = gpnetwork.predict(xtest, return_std=True)\n",
    "    return y_pred, sigma\n",
    "\n",
    "# https://github.com/fmfn/BayesianOptimization/blob/master/bayes_opt/util.py\n",
    "\n",
    "# Acquisition functions\n",
    "def upperConfidenceBound(xdata,gpnetwork,ybest,epsilon):\n",
    "    \"\"\"\n",
    "        xdata: input feature vectors or PCs of the REMAINING set\n",
    "        gpnetwork: GPR model\n",
    "        ybest: GPR-predicted best output property of the TRAINING set\n",
    "        epsilon: control exploration/exploitation. Higher epsilon means more exploration\n",
    "    \"\"\"\n",
    "    ye_pred, esigma = gprediction(gpnetwork, xdata)\n",
    "    ucb = np.empty(ye_pred.size, dtype=float)\n",
    "    for ii in range(0,ye_pred.size):\n",
    "        if esigma[ii] > 0:\n",
    "            ucb[ii]=(ye_pred[ii]+epsilon*esigma[ii])\n",
    "        else:\n",
    "            ucb[ii]=0.0\n",
    "    return ucb\n",
    "\n",
    "def probabilityOfImprovement(xdata,gpnetwork,ybest,epsilon):  \n",
    "    ye_pred, esigma = gprediction(gpnetwork, xdata)\n",
    "    poI = np.empty(ye_pred.size, dtype=float)\n",
    "    for ii in range(0,ye_pred.size):\n",
    "        if esigma[ii] > 0:\n",
    "            zzval=(ye_pred[ii]-ybest-epsilon)/float(esigma[ii])\n",
    "            poI[ii]=norm.cdf(zzval)\n",
    "        else:\n",
    "            poI[ii]=0.0\n",
    "    return poI\n",
    "\n",
    "def expectedImprovement(xdata,gpnetwork,ybest,epsilon): \n",
    "    ye_pred, esigma = gprediction(gpnetwork, xdata)\n",
    "    expI = np.empty(ye_pred.size, dtype=float)\n",
    "    for ii in range(0,ye_pred.size):\n",
    "        if esigma[ii] > 0:\n",
    "            zzval=(ye_pred[ii]-ybest)/float(esigma[ii])\n",
    "            expI[ii]=(ye_pred[ii]-ybest-epsilon)*norm.cdf(zzval)+esigma[ii]*norm.pdf(zzval)\n",
    "        else:\n",
    "            expI[ii]=0.0\n",
    "    return expI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the model\n",
    "## Select 10 initial random molecules for property (E$^{ox}$) evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = X.shape[0]   # Length of all data or number of molecules in the dataset\n",
    "ntrainInit = 10 # Number of initial training data points\n",
    "nremain = ndata - ntrainInit\n",
    "np.random.seed(10) # Fix the seed value\n",
    "dataset = np.random.permutation(ndata)\n",
    "a1data = np.empty(ntrainInit, dtype=int)\n",
    "a2data = np.empty(nremain, dtype=int)\n",
    "a1data[:] = dataset[0:ntrainInit]\n",
    "a2data[:] = dataset[ntrainInit:ndata]\n",
    "\n",
    "Xtrain = np.ndarray(shape=(ntrainInit, n_PC), dtype=float)\n",
    "XtrainSmiles = np.chararray(ntrainInit, itemsize=100)\n",
    "Ytrain = np.zeros(ntrainInit, dtype=float)\n",
    "Xtrain[0:ntrainInit, :] = Xdata[a1data, :]\n",
    "XtrainSmiles[0:ntrainInit] = Xsmiles[a1data]\n",
    "\n",
    "Xremain = np.ndarray(shape=(nremain, n_PC), dtype=float)\n",
    "XremainSmiles = np.chararray(nremain, itemsize=100)\n",
    "Yremain = np.empty(nremain, dtype=float)\n",
    "Xremain[0:nremain, :] = Xdata[a2data, :]\n",
    "XremainSmiles[0:nremain] = Xsmiles[a2data]\n",
    "#Yremain[0:nremain] = Ydata[a2data]\n",
    "\n",
    "print('*** Initial training set ***')\n",
    "print(115*'-')\n",
    "print('{:<5s}{:<80s}{:<15s}'.format('ID','SMILES','Eox (V vs. NHE)'))\n",
    "print(115*'-')\n",
    "for i in range(ntrainInit):\n",
    "    print('{:<5d}{:<80s}{:<15f}'.format(i,XtrainSmiles[i].decode(),Ytrain[i]))\n",
    "print(115*'-')  \n",
    "print(\"Total number of inital training points: \", ntrainInit)\n",
    "print(\"Total number of remaining points: \", nremain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate E$^{ox}$ of the intial training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computedEox = \"https://github.com/AIScienceTutorial/Bayesian-optimization---case-study/blob/main/computedEox.csv?raw=true\"\n",
    "dfEox = pd.read_csv(computedEox) # Load computed Eox \n",
    "\n",
    "def lookupComputedEox(smiles):  # Look up function for computed Eox values\n",
    "    smilesLoc = dfSMILES[dfSMILES.SMILES == smiles].index[0]\n",
    "    return dfEox.iloc[smilesLoc].values[0]\n",
    "\n",
    "for i,sml in enumerate(XtrainSmiles.decode()):  # Read computed Eox into the intial training set\n",
    "    Ytrain[i] = lookupComputedEox(sml)\n",
    "\n",
    "yoptLoc = np.argmax(Ytrain)\n",
    "yopttval = Ytrain[yoptLoc]\n",
    "xoptSmiles = XtrainSmiles[yoptLoc].decode()\n",
    "yoptstep=0\n",
    "yopinit = yopttval\n",
    "ntrain = ntrainInit\n",
    "print('*** Initial training set ***')\n",
    "print(115*'-')\n",
    "print('{:<5s}{:<80s}{:<15s}'.format('ID','SMILES','Eox (V vs. NHE)'))\n",
    "print(115*'-')\n",
    "for i in range(ntrain):\n",
    "    print('{:<5d}{:<80s}{:<15f}'.format(i,XtrainSmiles[i].decode(),Ytrain[i]))\n",
    "print(115*'-')  \n",
    "print(\"Total number of inital training points: \", ntrainInit)\n",
    "print(\"Initial best SMILES is \"+xoptSmiles+' with computed Eox = '+str(yopttval)+' V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Bayesian optimization cycles (Any question?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Train GPR model and make predictions. Refer to workflow figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_size_inches(10,8)\n",
    "titleSize=30\n",
    "axisTitleSize=20\n",
    "markerSize=50\n",
    "\n",
    "fig.suptitle('Trained GPR model on '+str(ntrain)+' data points',fontsize=titleSize)\n",
    "gpnetwork = gpregression(Xtrain, Ytrain, n_PC)\n",
    "\n",
    "yt_pred, tsigma = gprediction(gpnetwork, Xtrain)\n",
    "ybestloc = np.argmax(Ytrain) # The current best y value\n",
    "ybest_pred = yt_pred[ybestloc]\n",
    "axs[0,0].scatter(np.arange(len(yt_pred)),yt_pred,color='limegreen',s=markerSize)\n",
    "axs[0, 0].set_title('Train', fontsize=axisTitleSize)\n",
    "axs[1,0].scatter(np.arange(len(tsigma)),tsigma,color='limegreen',marker='d',s=markerSize)\n",
    "axs[0,0].scatter(ybestloc,ybest_pred,color='r',marker='s',s=markerSize+50,facecolor='None')\n",
    "\n",
    "yr_pred, rsigma = gprediction(gpnetwork, Xremain)\n",
    "axs[0,1].scatter(np.arange(len(yr_pred)),yr_pred,color='b',s=markerSize)\n",
    "axs[0, 1].set_title('Remain',fontsize=axisTitleSize)\n",
    "axs[1,1].scatter(np.arange(len(rsigma)),rsigma,color='b',marker='d',s=markerSize)\n",
    "\n",
    "axs[0,0].set_ylabel('Predicted Eox (V)',fontsize=axisTitleSize)\n",
    "axs[1,0].set_xlabel('Index',fontsize=axisTitleSize)\n",
    "axs[1,0].set_ylabel('Predicted 1$\\sigma$ (V)',fontsize=axisTitleSize)\n",
    "axs[1,1].set_xlabel('Index',fontsize=axisTitleSize)\n",
    "\n",
    "rmse = np.sqrt(np.mean((yt_pred-Ytrain)**2))\n",
    "print('Current GPR error in V: RMSE = ', rmse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate the Acquisition Function and suggest next data point/molecule for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.set_size_inches(8,10)\n",
    "\n",
    "print('Computing EI on the remaining '+str(ndata-ntrain)+' data points')\n",
    "epsilon = 0.01 # Control exploration/exploitation\n",
    "expI = expectedImprovement(Xremain, gpnetwork, ybest_pred, epsilon)\n",
    "AFmax = np.max(expI)\n",
    "AFmaxloc = np.argmax(expI)\n",
    "XSmilesNew = XremainSmiles[AFmaxloc].decode()\n",
    "\n",
    "axs[0].scatter(np.arange(len(yr_pred)),yr_pred,color='b',s=markerSize)\n",
    "axs[0].axvline(AFmaxloc,color='r',ls='--')\n",
    "axs[0].set_ylabel('Predicted Eox (V)',fontsize=axisTitleSize)\n",
    "\n",
    "axs[1].scatter(np.arange(len(rsigma)),rsigma,color='b',marker='d',s=markerSize)\n",
    "axs[1].axvline(AFmaxloc,color='r',ls='--')\n",
    "axs[1].set_ylabel('Predicted 1$\\sigma$ (V)',fontsize=axisTitleSize)\n",
    "\n",
    "\n",
    "axs[2].scatter(np.arange(len(expI)),expI,color='b',marker='*',s=markerSize)\n",
    "axs[2].scatter(AFmaxloc,AFmax,edgecolor='r',marker='s',s=markerSize+50,facecolor='None')\n",
    "axs[2].axvline(AFmaxloc,color='r',ls='--')\n",
    "axs[2].set_xlabel('Index',fontsize=axisTitleSize)\n",
    "axs[2].set_ylabel('Computed AF',fontsize=axisTitleSize)\n",
    "\n",
    "plt.show()\n",
    "print('Based on the evalulate AF, the next SMILES to be evaluated is '+XSmilesNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the next data point and add to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEoxNew = lookupComputedEox(XremainSmiles[AFmaxloc].decode())\n",
    "ybestloc = np.argmax(Ytrain) # The current best y value\n",
    "ytrue = Ytrain[ybestloc]\n",
    "\n",
    "if yopttval < YEoxNew:  # Identify current SMILES with maximum computed Eox\n",
    "    yopttval = YEoxNew\n",
    "    xoptSmiles = XtrainSmiles[ybestloc]\n",
    "\n",
    "if XSmilesNew in XtrainSmiles:\n",
    "    print(\"New SMILES is already in train set\")  \n",
    "else:\n",
    "    print('Added '+XSmilesNew+' with Eox='+str(YEoxNew)+' V to the training set')\n",
    "    xtnewSmiles = np.append(XtrainSmiles, XSmilesNew)\n",
    "    ytnew = np.append(Ytrain, YEoxNew)\n",
    "    xtnew = np.append(Xtrain, Xremain[AFmaxloc]).reshape(-1, n_PC)\n",
    "\n",
    "    xrnew = np.delete(Xremain, AFmaxloc, 0)\n",
    "    xrnewSmiles = np.delete(XremainSmiles, AFmaxloc)\n",
    "\n",
    "    Xtrain = xtnew\n",
    "    XtrainSmiles = xtnewSmiles\n",
    "    Ytrain = ytnew\n",
    "\n",
    "    Xremain = xrnew\n",
    "    XremainSmiles = xrnewSmiles\n",
    "    del xtnew, xtnewSmiles, ytnew, xrnew, xrnewSmiles\n",
    "\n",
    "ntrain = len(XtrainSmiles)\n",
    "nremain = len(XremainSmiles)\n",
    "print('*** Current training set ***')\n",
    "print(115*'-')\n",
    "print('{:<5s}{:<80s}{:<15s}'.format('ID','SMILES','Eox (V vs. NHE)'))\n",
    "print(115*'-')\n",
    "for i in range(ntrain):\n",
    "    print('{:<5d}{:<80s}{:<15f}'.format(i,XtrainSmiles[i],Ytrain[i]))\n",
    "print(115*'-')  \n",
    "print('Total number of training points: ', ntrain)\n",
    "print('Total number of remaining points: ',nremain)\n",
    "print('Current best SMILES (id= '+str(np.argmax(Ytrain))+'), is '+xoptSmiles+' with computed Eox = '+str(yopttval)+' V')\n",
    "print('***Go back to step 1 to repeat the BO loop***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine initilization with Bayesian optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BayesOpt(Xdata,Ydata,Xinfo,ndata,nPC,eps,af):\n",
    "    ntrain = 10 # Number of initial training data points\n",
    "    nremain = ndata - ntrain\n",
    "    dataset = np.random.permutation(ndata)\n",
    "    a1data = np.empty(ntrain, dtype=int)\n",
    "    a2data = np.empty(nremain, dtype=int)\n",
    "    a1data[:] = dataset[0:ntrain]\n",
    "    a2data[:] = dataset[ntrain:ndata]\n",
    "\n",
    "    Xtrain = np.ndarray(shape=(ntrain, nPC), dtype=float)\n",
    "    Xtraininfo = np.chararray(ntrain, itemsize=100)\n",
    "    Ytrain = np.empty(ntrain, dtype=float)\n",
    "    Xtrain[0:ntrain, :] = Xdata[a1data, :]\n",
    "    Xtraininfo[0:ntrain] = Xinfo[a1data]\n",
    "    Ytrain[0:ntrain] = Ydata[a1data]\n",
    "    \n",
    "    yoptLoc = np.argmax(Ytrain)\n",
    "    yopttval = Ytrain[yoptLoc]\n",
    "    xoptval = Xtraininfo[yoptLoc]\n",
    "    yoptstep=0\n",
    "    yopinit = yopttval\n",
    "    xoptint = xoptval\n",
    "\n",
    "    Xremain = np.ndarray(shape=(nremain, nPC), dtype=float)\n",
    "    Xremaininfo = np.chararray(nremain, itemsize=100)\n",
    "    Yremain = np.empty(nremain, dtype=float)\n",
    "    Xremain[0:nremain, :] = Xdata[a2data, :]\n",
    "    Xremaininfo[0:nremain] = Xinfo[a2data]\n",
    "    Yremain[0:nremain] = Ydata[a2data]\n",
    "    \n",
    "    print('*** Initial training set ***')\n",
    "    print(115*'-')\n",
    "    print('{:<5s}{:<80s}{:<15s}'.format('Id','SMILES','Eox'))\n",
    "    print(115*'-')\n",
    "    for i in range(ntrain):\n",
    "        print('{:<5d}{:<80s}{:<15f}'.format(i,Xtraininfo[i].decode(),Ytrain[i]))\n",
    "    print(115*'-')  \n",
    "\n",
    "    print(\"Total number of inital training points: \", ntrain)\n",
    "    print(\"Initial best SMILES is \"+xoptval.decode()+' with Eox = '+str(yopttval)+' V')\n",
    "    \n",
    "    for ii in tqdm(range(0, Niteration),desc='Progress'):\n",
    "        gpnetwork = gpregression(Xtrain, Ytrain, nPC)\n",
    "        yt_pred, tsigma = gprediction(gpnetwork, Xtrain)\n",
    "        ybestloc = np.argmax(Ytrain) # The current best y value\n",
    "        ybest = yt_pred[ybestloc]\n",
    "        ytrue = Ytrain[ybestloc]\n",
    "        \n",
    "        if yopttval < ytrue:\n",
    "            yopttval = ytrue\n",
    "            xoptval = Xtraininfo[ybestloc]\n",
    "            \n",
    "        if af=='EI':\n",
    "            afValues = expectedImprovement(Xremain, gpnetwork, ybest, eps)    \n",
    "        elif af=='POI':\n",
    "            afValues = probabilityOfImprovement(Xremain, gpnetwork, ybest, eps)\n",
    "        elif af=='UCB':\n",
    "            afValues = upperConfidenceBound(Xremain, gpnetwork, ybest, eps)\n",
    "\n",
    "        afMax = np.max(afValues)\n",
    "        afmaxloc = np.argmax(afValues)\n",
    "        \n",
    "        xnew = np.append(Xtrain, Xremain[afmaxloc]).reshape(-1, nPC)\n",
    "        xnewinfo = np.append(Xtraininfo, Xremaininfo[afmaxloc])\n",
    "        ynew = np.append(Ytrain, Yremain[afmaxloc])\n",
    "        xrnew = np.delete(Xremain, afmaxloc, 0)\n",
    "        xrnewinfo = np.delete(Xremaininfo, afmaxloc)\n",
    "        yrnew = np.delete(Yremain, afmaxloc)\n",
    "        if ii==0:\n",
    "            Xexplored=Xremaininfo[afmaxloc]\n",
    "            Yexplored=Yremain[afmaxloc]\n",
    "        else:\n",
    "            Xexploredtemp=np.append(Xexplored, Xremaininfo[afmaxloc])\n",
    "            Yexploredtemp=np.append(Yexplored, Yremain[afmaxloc])\n",
    "            del Xexplored,Yexplored\n",
    "            Xexplored=Xexploredtemp\n",
    "            Yexplored=Yexploredtemp\n",
    "        del Xtrain, Ytrain, Xremaininfo, gpnetwork\n",
    "        Xtrain = xnew\n",
    "        Xtraininfo = xnewinfo\n",
    "        Ytrain = ynew\n",
    "        Xremain = xrnew\n",
    "        Xremaininfo = xrnewinfo\n",
    "        Yremain = yrnew\n",
    "        del xnew, xnewinfo, ynew, xrnew, xrnewinfo, yrnew\n",
    "\n",
    "    if not yopinit==yopttval:\n",
    "        yoptstep = np.argmax(Yexplored) + 1       \n",
    "    else:\n",
    "        yoptstep=0\n",
    "    dataorder = np.argsort(Yexplored)\n",
    "    Yexploredtemp=Yexplored[dataorder]\n",
    "    Xexploredtemp = Xexplored[dataorder]\n",
    "    print('*** Summary ***')\n",
    "    print(115*'-')\n",
    "    print('{:<15s}{:<80s}{:<15s}'.format('Iteration','SMILES','Eox'))\n",
    "    print(115*'-')\n",
    "    for i,sml in enumerate(Xexplored):   \n",
    "        print('{:<15d}{:<80s}{:<15f}'.format(i+1,sml.decode(),Yexplored[i]))\n",
    "    print(115*'-')  \n",
    "    print(\"\\n\")\n",
    "    print(\"The best SMILES is \"+xoptval.decode()+\" with Eox = \"+str(yopttval)+\" V, which was found in iteration \"+str(yoptstep))\n",
    "    return xoptint,yopinit,xoptval,yopttval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a number of BO cycles continously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computedEox = \"https://github.com/AIScienceTutorial/Bayesian-optimization---case-study/blob/main/computedEox.csv?raw=true\"\n",
    "dfEox = pd.read_csv(computedEox) # Load pre-computed Eox \n",
    "Ydata = dfEox.Eox.values \n",
    "print('*** Finding SMILES with maximum Eox ***')\n",
    "ndata = len(Ydata)\n",
    "print(\"Original shape of X and Y :\",np.shape(Xdata),np.shape(Ydata))\n",
    "epsilon=0.01\n",
    "acquiFunc='EI'  # POI, UCB\n",
    "Nruns=1 # for statistics\n",
    "Niteration = 15   # number of iteration in a given Bayesian  Optimization\n",
    "Xinitguess = np.chararray(Nruns,itemsize=100)\n",
    "Yinitguess = np.empty(Nruns,dtype=float)\n",
    "Xoptimal = np.chararray(Nruns,itemsize=100)\n",
    "Yoptimal = np.empty(Nruns,dtype=float)\n",
    "\n",
    "for ii in range(0,Nruns):\n",
    "    print('Run ',ii)\n",
    "    Xinitguess[ii], Yinitguess[ii], Xoptimal[ii], Yoptimal[ii] = BayesOpt(Xdata, Ydata, Xsmiles, ndata, n_PC,epsilon,acquiFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The solution\n",
    "print('\\n The true maximum Eox is '+str(np.max(Ydata))+' V which belongs to '+Xsmiles[np.argmax(Ydata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Bayesian optimization to random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxRandomIter=[]\n",
    "for i in range(100):\n",
    "    randomArray = np.random.permutation(len(Xsmiles))\n",
    "    loc = np.argmax(Ydata[randomArray])\n",
    "    maxRandomIter.append(loc)\n",
    "maxRandomIter = np.array(maxRandomIter)\n",
    "print('Random selection requires '+str(int(maxRandomIter.mean()))+'+/-'+str(int(maxRandomIter.std()))+' iterations to find the SMILES with maximum Eox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlmat] *",
   "language": "python",
   "name": "conda-env-mlmat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
